{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e83807b",
   "metadata": {},
   "source": [
    "# Lab 2: Evaluating an N-Gram Language Model\n",
    "\n",
    "In this lab, you will evaluate the quality of an n-gram language model using perplexity.\n",
    "\n",
    "We have built several n-gram language models and provided an implementation for computing the probabilities. The implementation includes [Laplace Smoothing](https://en.wikipedia.org/wiki/Additive_smoothing), with assigns some probability to sequences that were never encountered during training.\n",
    "\n",
    "First, review the implementation below to make sure that it makes sense to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26008ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "OOV = '<OOV>'\n",
    "class NGramLM:\n",
    "    def __init__(self, path, smoothing=0.01, verbose=False):\n",
    "        with open(path, 'rb') as fin:\n",
    "            data = pickle.load(fin)\n",
    "        self.n = data['n']\n",
    "        self.V = set(data['V'])\n",
    "        self.model = data['model']\n",
    "        self.smoothing = smoothing\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def get_prob(self, context, token):\n",
    "        \n",
    "        # Take only the n-1 most recent context (Markov Assumption)\n",
    "        context = tuple(context[-self.n+1:])\n",
    "        # Add <BOS> tokens if the context is too short, i.e., it's at the start of the sequence\n",
    "        while len(context) < (self.n-1):\n",
    "            context = (BOS,) + context\n",
    "        # Handle words that were not encountered during the training by replacing them with a special <OOV> token\n",
    "        context = tuple((c if c in self.V else OOV) for c in context)\n",
    "        if token not in self.V:\n",
    "            token = OOV\n",
    "        if context in self.model:\n",
    "            # Compute the probability using a Maximum Likelihood Estimation and Laplace Smoothing\n",
    "            count = self.model[context].get(token, 0)\n",
    "            prob = (count + self.smoothing) / (sum(self.model[context].values()) + self.smoothing * len(self.V))\n",
    "        else:\n",
    "            # Simplified formula if we never encountered this context; the probability of all tokens is uniform\n",
    "            prob = 1 / len(self.V)\n",
    "        # Optional logging\n",
    "        if self.verbose:\n",
    "            print(f'{prob:.4n}', *context, '->', token)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1365f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-built n-gram languae models\n",
    "model_unigram = NGramLM('arthur-conan-doyle.tok.train.n1.pkl')\n",
    "model_bigram = NGramLM('arthur-conan-doyle.tok.train.n2.pkl')\n",
    "model_trigram = NGramLM('arthur-conan-doyle.tok.train.n3.pkl')\n",
    "model_4gram = NGramLM('arthur-conan-doyle.tok.train.n4.pkl')\n",
    "model_5gram = NGramLM('arthur-conan-doyle.tok.train.n5.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca2a36c",
   "metadata": {},
   "source": [
    "Now it's time to see how well these models fit our data! We'll use Perplexity for this calculation, but it's up to you to implement it below.\n",
    "\n",
    "Recall the formula for perplexity from the lecture:\n",
    "\n",
    "$$\n",
    "perplexity = 2^{\\frac{-1}{n}\\sum \\log_2(P(w_i|w_{<i}))}\n",
    "$$\n",
    "\n",
    "Hint: you'll want to use the [`math.log2`](https://docs.python.org/3/library/math.html#math.log2) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e21eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7530.614613660964"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import math\n",
    "\n",
    "def perplexity(model: NGramLM, texts: List[Tuple[str]]) -> float:\n",
    "\n",
    "    n_word = 0\n",
    "\n",
    "    res = 0\n",
    "\n",
    "    for text in texts:\n",
    "\n",
    "        n_word += len(text)\n",
    "\n",
    "        for i in range(len(text)):\n",
    "\n",
    "            res += math.log2(model.get_prob(text[:i], text[i]))\n",
    "\n",
    "    res = 2 ** ((-1 / n_word) * res)\n",
    "\n",
    "    return res\n",
    "\n",
    "# Example:\n",
    "# perplexity(model_unigram, [('My', 'dear', 'Watson', '.'), ('Come', 'over', 'here', '!')])\n",
    "perplexity(model_unigram, [('My', 'dear', 'Watson')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac852573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "assert round(perplexity(model_unigram, [('My', 'dear', 'Watson')])) == 7531\n",
    "assert round(perplexity(model_bigram, [('My', 'dear', 'Watson')])) == 24\n",
    "assert round(perplexity(model_trigram, [('My', 'dear', 'Watson')])) == 521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2643d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14924.23177561972\n",
      "259.53894955494343\n",
      "1306.553535960716\n",
      "4921.800243745181\n",
      "8463.320537397633\n"
     ]
    }
   ],
   "source": [
    "toks_test = []\n",
    "\n",
    "with open('arthur-conan-doyle.tok.test.txt', 'rt') as fin:\n",
    "    for line in fin:\n",
    "        toks_test.append(list(line.split()))\n",
    "\n",
    "print(perplexity(model_unigram, toks_test))\n",
    "print(perplexity(model_bigram, toks_test))\n",
    "print(perplexity(model_trigram, toks_test))\n",
    "print(perplexity(model_4gram, toks_test))\n",
    "print(perplexity(model_5gram, toks_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66a1e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14976.720310596447\n",
      "89.24191939089853\n",
      "91.8592986931776\n",
      "121.15467462849904\n",
      "137.07146227562924\n"
     ]
    }
   ],
   "source": [
    "toks_train = []\n",
    "with open('arthur-conan-doyle.tok.train.txt', 'rt') as fin:\n",
    "    for line in fin:\n",
    "        toks_train.append(list(line.split()))\n",
    "\n",
    "# your code here\n",
    "print(perplexity(model_unigram, toks_train))\n",
    "print(perplexity(model_bigram, toks_train))\n",
    "print(perplexity(model_trigram, toks_train))\n",
    "print(perplexity(model_4gram, toks_train))\n",
    "print(perplexity(model_5gram, toks_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9301b5d9",
   "metadata": {},
   "source": [
    "We can see that we get much lower perplexities when measuring on the training data, especially for the models with larger values of `n`. This suggests that the model is over-fitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86942276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (nn)",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
